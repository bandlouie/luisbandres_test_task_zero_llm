{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd71328-abaa-4768-8269-82c8a1b5ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import markdown\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import IPython.display\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb4ab6d-5c80-46aa-b493-91d4b294ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9886b95c-1f14-4a70-b1ea-5cb0200e2d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f469b2-52ba-4565-b9e6-173b0d9717ba",
   "metadata": {},
   "source": [
    "## LLM Mapping Chain\n",
    "\n",
    "It doesn't need history for completion. Therefore, is token-efficiente and it doesn't require the memory of GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2376ab46-b819-4e13-94ed-b656bb1ac67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_template_file_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You will be provided with a table in a markdown format as << INPUT >>.\n",
    "\n",
    "If there is not a markdown table in the input return an empty JSON object. Otherwise, return a JSON object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{\n",
    "    \"template_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column. If the input does not contain a header suggest a name for the column based on its data.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "            \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "            \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ descrption of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ]\n",
    "}}}}\n",
    "\n",
    "\n",
    "<< INPUT >>\n",
    "{input_template}\n",
    "\n",
    "<< OUTPUT >>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a66e69e-6636-4e2e-8fe4-abb09dcfbac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_file_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You will be provided with a table in a markdown format as << INPUT >>.\n",
    "Also you will provided with the name of the table as << TABLE >>\n",
    "\n",
    "If there is not a markdown table in the input return an empty JSON object. Otherwise, return a JSON object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it at the begining of the input.\n",
    "    \"file_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column. If the input does not contain a header suggest a name for the column based on its data.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"date_format\": string, \\ null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ description of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "    \"table\" : string \\ the complete markdown table in the input\n",
    "}}}}\n",
    "\n",
    "<< TABLE >>\n",
    "{table_name}\n",
    "\n",
    "<< INPUT >>\n",
    "{input_file}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Only return a JSON Object, no more!! The only valid output is a JSON Object.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b5e5ab3-39b1-47cb-8829-17dc9cb5828f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_header_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive two JSON Objects called table_info and template_description as inputs << INPUT >.\n",
    "\n",
    "Follow the following instruction:\n",
    "\n",
    "    Step 1: Go over the list table_info['file_metadata'] and find what is the N header in the list template_description['template_metadata'] most similar to the \"new_file\" table header.\n",
    "    Step 2: return the same \"table_info\" JSON object adding the following information:\n",
    "\n",
    "\"header_match\": [\n",
    "        {{{{\n",
    "            \"table_header\": string, \\ header of \"new_file\" table most similar to the N header of \"template\" table\n",
    "            \"template_header\": string, \\ header of \"template\" table\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "\n",
    "\"template_header\" is the N header of \"template\" table most similar to the correspoding header of \"new_file\" table. Determine this similarity based only on the metadata such as:\n",
    "    * Data types\n",
    "    * Samples of both tables\n",
    "    * Description\n",
    "\n",
    "<< INPUT >>\n",
    "{table_info}\n",
    "{template_description}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Only return a JSON Object, no more!! The only valid output is a JSON Object.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e043046-b6c4-4347-842a-7d620a918a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_proposal_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive two JSON Objects called table_header_match and template_description as inputs << INPUT >.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "    \n",
    "    Step 1: Go over the list table_header_match[\"header_match\"].\n",
    "    Step 2: For each one of the table_header_match[\"header_match\"][\"table_header\"], replace the header of the markdown table in table_header_match[\"table\"] by table_header_match[\"header_match\"][\"template_header\"]\n",
    "    Step 3: The new markdown table must have only the columns in listed in table_header_match[\"header_match\"][\"template_header\"]. Remove all the remaining columns different to table_header_match[\"header_match\"][\"template_header\"].\n",
    "\n",
    "Return the new markdown table in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_header_match[\"table_name\"].\n",
    "    \"file_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "            \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "            \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ descrption of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "    \"modified_table\" : string, \\ the new markdown table.\n",
    "    \"template_metadata\": template_description[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_header_match}\n",
    "{template_description}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Only return a JSON Object, no more!! The only valid output is a JSON Object.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78000db-e16d-4dfa-836b-2e17203b1c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_categories_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called simple_table as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to find the column in the \"modified_table\" that is most similar to the N header in the \"template_metadata\" list. Then, select only the categorical columns and return the \"simple_table\" JSON object with the added information.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: compare the headers in the \"modified_table\" with the headers in the \"template_metadata\" list. We will  iterate over the columns in the \"modified_table\" and find the column that is most similar to the N header in the \"template_metadata\" list.\n",
    "Step 2: After finding the most similar column, check if it is a categorical column by checking the \"categorical\" key in the \"file_metadata\" list.\n",
    "Step 3: Add the following information to the \"simple_table\" JSON object.\n",
    "Step 4: Return the updated  \"simple_table\" JSON object.\n",
    "\n",
    "\"categories_match\": [\n",
    "    {{{{\n",
    "        \"categories_list\": string, \\ list of categories in simple_table['template_metadata']\n",
    "        \"table_header\": string, \\ header of markdown table in simple_table[\"modified_table\"] most similar to the N header of \"template_metadata\"\n",
    "    }}}},\n",
    "    ...\n",
    "],\n",
    "\n",
    "<< INPUT >>\n",
    "{simple_table}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return the updated  \"simple_table\" JSON object. Only return a JSON Object, no more!! The only valid output is a JSON Object.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc4766f-7d4a-4b96-90c5-178313553147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories_result_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_categories_match as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to generate a markdown table by replacing each value in the categorical columns of the \"modified_table\" with the most similar item from the \"categories_list\" in the \"categories_match\" section. The updated table should be returned as a JSON object.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: Iterate over each categorical column in the \"modified_table\".\n",
    "Step 2: Replace each value in the column with the most similar item from the \"categories_list\" in the \"categories_match\" section.\n",
    "Setp 3: the new markdown table will be called correct_cats_markdown_table\n",
    "\n",
    "Return the new markdown table (correct_cats_markdown_table) in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_categories_match[\"table_name\"].\n",
    "    \"file_metadata\": [\n",
    "    {{{{\n",
    "        \"header\": string, \\ name of the column.\n",
    "        \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "        \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "        \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "        \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "        \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "        \"description\": string \\ descrption of this column based only on its data.\n",
    "    }}}},\n",
    "    ...\n",
    "    ],\n",
    "    \"table\" : string, \\ the new markdown table (correct_cats_markdown_table).\n",
    "    \"template_metadata\": table_categories_match[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_categories_match}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return only the JSON Object. Only return a JSON Object, no more!! The only valid output is a JSON Object.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1c545e-ae06-48fc-967f-99f5b998004b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_dates_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_categories_result as input << INPUT >.\n",
    "\n",
    "Change the format of each one the rows of date columns in the markdown in table_categories_result[\"table\"] according to the date format in the list table_categories_result[\"template_metadata\"]\n",
    "\n",
    "The new markdown table will be called correct_dates_markdown_table\n",
    "\n",
    "Return the new markdown table (correct_dates_markdown_table) in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_categories_result[\"table_name\"].\n",
    "    \"table\" : string, \\ the new markdown table (correct_dates_markdown_table).\n",
    "    \"template_metadata\": table_categories_result[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_categories_result}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return only the JSON Object. Only return a JSON Object, no more!! The only valid output is a JSON Object.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5eae172-ad8b-48dd-b874-916a2bc0948b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_strings_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_dates_result as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to find the column in the markdown \"table\" that is most similar to the N header in the \"template_metadata\" list. Then, select only the string columns and return the \"table_dates_result\" JSON object with the added information.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: compare the headers in the \"table\" with the headers in the \"template_metadata\" list. We will  iterate over the columns in the \"table\" and find the column that is most similar to the N header in the \"template_metadata\" list.\n",
    "Step 2: After finding the most similar column, check if it is a string column by checking the \"type\" key in the \"file_metadata\" list.\n",
    "Step 3: Ignore if it is a categorical, numerical or date column by checking the \"categorical\" key in the \"file_metadata\" list.\n",
    "Step 4: Add the following information to the \"table_dates_result\" JSON object.\n",
    "Step 5: Transform all the rows of string columns of markdown table so they look like than their columns in \"template_metadata\".\n",
    "Step 5: Return the updated  \"table_dates_result\" JSON object.\n",
    "\n",
    "\"strings_match\": [\n",
    "    {{{{\n",
    "        \"selected_sample\": string, \\ sample of data in table_dates_result[\"template_metadata\"]\n",
    "        \"table_header\": string, \\ header of markdown table in table_dates_result[\"table\"] most similar to the N header of \"template_metadata\"\n",
    "    }}}},\n",
    "    ...\n",
    "],\n",
    "\n",
    "<< INPUT >>\n",
    "{table_dates_result}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return the updated \"table_dates_result\" JSON object. Only return a JSON Object, no more!! The only valid output is a JSON Object.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad655a7-5623-47d2-a44f-0dc1c0dcefce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_template_load = LLMChain(llm=llm, prompt=load_template_file_prompt, \n",
    "                     output_key=\"template_description\"\n",
    "                    )\n",
    "chain_load = LLMChain(llm=llm, prompt=load_file_prompt, \n",
    "                     output_key=\"table_info\"\n",
    "                    )\n",
    "chain_header_formatting = LLMChain(llm=llm, prompt=formating_header_prompt, \n",
    "                     output_key=\"table_header_match\"\n",
    "                    )\n",
    "chain_proposal = LLMChain(llm=llm, prompt=table_proposal_prompt, \n",
    "                     output_key=\"simple_table\"\n",
    "                    )\n",
    "chain_cats_formatting = LLMChain(llm=llm, prompt=formating_categories_prompt, \n",
    "                     output_key=\"table_categories_match\"\n",
    "                    )\n",
    "chain_cats_result = LLMChain(llm=llm, prompt=categories_result_prompt, \n",
    "                     output_key=\"table_categories_result\"\n",
    "                    )\n",
    "chain_dates_result = LLMChain(llm=llm, prompt=formating_dates_prompt, \n",
    "                     output_key=\"table_dates_result\"\n",
    "                    )\n",
    "chain_strings_formatting = LLMChain(llm=llm, prompt=formating_strings_prompt, \n",
    "                     output_key=\"table_strings_match\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118147fe-30ab-40d3-8f5c-898d25bc481d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_chain = SequentialChain(\n",
    "    chains=[chain_template_load, chain_load, chain_header_formatting, chain_proposal, chain_cats_formatting, chain_cats_result, chain_dates_result, chain_strings_formatting],\n",
    "    input_variables=[\"input_template\",\"table_name\",\"input_file\"],\n",
    "    output_variables=[\"table_header_match\",\"table_categories_match\",\"table_strings_match\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8edb3-de6f-4a82-b550-e9c4c8ac6a7f",
   "metadata": {},
   "source": [
    "## LLM Coding Chain\n",
    "\n",
    "It doesn't need history for completion. Therefore, is token-efficiente and it doesn't require the memory of GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddecb26-abe6-4f97-856e-450b8504ddac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_data_attributes(analysis_chain):\n",
    "    return dict(\n",
    "        # Inputs\n",
    "        template_table = analysis_chain['input_template'],\n",
    "        initial_table = analysis_chain['input_file'],\n",
    "        # Metadata\n",
    "        file_metadata = json.loads(analysis_chain['table_header_match'])['file_metadata'],\n",
    "        template_metadata = json.loads(analysis_chain['table_categories_match'])['template_metadata'],\n",
    "        # Feature Mappings\n",
    "        header_match = json.loads(analysis_chain['table_header_match'])['header_match'],\n",
    "        categories_match = json.loads(analysis_chain['table_categories_match'])['categories_match'],\n",
    "        strings_match = json.loads(analysis_chain['table_strings_match'])['strings_match'],\n",
    "        # Final Table\n",
    "        final_table = json.loads(analysis_chain['table_strings_match'])['table']\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df4ab425-3962-41d7-8e6e-0e8089de4a08",
   "metadata": {
    "tags": []
   },
   "source": [
    "# def get_python_code_prompt():\n",
    "#     global execution_chain\n",
    "#     # try:\n",
    "#     map_process = extract_data_attributes(execution_chain)\n",
    "#     return f\"\"\"\n",
    "#     Also, you will be provided with a initial_table in a markdown format as << INITIAL_TABLE >>. You need to transform the initial_table to the same format than  template table.\n",
    "#     Finally, you will be provided with a template_table in a markdown format as << TEMPLATE_TABLE >>. The template_table is the expected result you need to achieve.\n",
    "\n",
    "#     The objective is to create a python code for transforming the initial_table into template_table. You need to use the mapping from renaming columns of initial_table to making their headers the same than template_table.\n",
    "\n",
    "\n",
    "#     Please follow the next 12 (twelve) steps for creating a python code:\n",
    "\n",
    "#     STEP 1: Load initial_table using pandas 1.3.1 as a dataframe.\n",
    "    \n",
    "#     STEP 2: Run this step if and only if any \"table_header\" in \"categories_list\" << CATEGORIES REQUIRED >>> is in initial_table headers. Omit this step if \"categories_list\" is an empty list.\n",
    "    \n",
    "#     Replace each value in the strings column with the most similar item from the \"categories_list\" << CATEGORIES REQUIRED >>>. The python code needs to replace each value in the categorical columns of the dataframe with the most similar item from the \"categories_list\" in the << CATEGORIES REQUIRED >>>.\n",
    "#     << CATEGORIES REQUIRED >>>\n",
    "#     ```json\n",
    "#     {json.dumps(map_process['categories_match'])}\n",
    "#     ```\n",
    "#     When calculate similarity, not use index [0] if difflib.get_close_matches() returns an empty list. In that case use the original category value.\n",
    "#     You need to implement in this step a code for calculating similarities between strings. All resulting categories columns must be string columns. Considers the previous steps.\n",
    "    \n",
    "#     STEP 3: Rename columns using HEADERS MAPPING. New headers names are in \"template_header\" section.\n",
    "#     << HEADERS MAPPING >>\n",
    "#     ```json\n",
    "#     {json.dumps(map_process['header_match'])}\n",
    "#     ```\n",
    "    \n",
    "#     STEP 3.5: Run the same processes in STEP if and only if any \"table_header\" in \"categories_list\" << CATEGORIES REQUIRED >>> is in updated initial_table headers. Omit this step if \"categories_list\" is an empty list.\n",
    "    \n",
    "#     STEP 4: In the following steps only consider the new headers of the columns assigned in STEP 3. Also discard other columns.\n",
    "\n",
    "#     STEP 5: Transform the date columns of inital_table to the same date format than template_table. Considers the previous steps.\n",
    "    \n",
    "#     STEP 6: Transform all the rows of string columns (except categories columns in STEP 3) of dataframe so they look like than their columns in template_table. Considers the previous steps.\n",
    "    \n",
    "#     STEP 7: Transform all the rows of columns (for serials) of dataframe so they look like than their columns (for serials) in template_table. Considers the previous steps.\n",
    "    \n",
    "#     STEP 8: Transform values in numeric columns of inital_table so they look like than their numeric columns in template_table. Considers the previous steps.\n",
    "\n",
    "#     STEP 9: Read all the code and be sure that all required libraries in the code are correctly imported. Considers the previous steps.\n",
    "    \n",
    "#     STEP 10: Fix all syntaxis errors for python 3.9.\n",
    "    \n",
    "#     STEP 11: Remove any duplicated column.\n",
    "\n",
    "#     STEP 12: Save the dataframe as csv file called \"transformed_table\".\n",
    "\n",
    "#     Remember the objective is to reproduce the template_table using python 3.9 or above.\n",
    "\n",
    "#     CONSTRAINTS\n",
    "#     a) Code will receive only initial_table as a csv file.\n",
    "#     b) Avoid inplae parameters in pandas transformations\n",
    "#     c) The code need to save the transformed table as csv.\n",
    "#     d) Categorical columns must be filled (not completely empty).\n",
    "#     d) you need to test that produced result table is exactly the same than template_table provided.\n",
    "#     e) You must return only a complete python script.\n",
    "#     f) template_table is only a markdown that only exists in this prompt for your guidance. final table is not a file nor is it a dataframe.\n",
    "#     g) template_table is ignored by the resulting python code.\n",
    "#     h) fix all syntaxis error for python 3.9\n",
    "\n",
    "#     << INITIAL_TABLE >>\n",
    "#     {json.dumps(map_process['initial_table'])}\n",
    "\n",
    "#     << TEMPLATE_TABLE >>\n",
    "#     {json.dumps(map_process['final_table'])}\n",
    "\n",
    "#     << OUTPUT >>\n",
    "#     You must return only a complete python script. Please avoid make extra comments, I need only the python script.\n",
    "\n",
    "#     \"\"\"\n",
    "#     # except Exception as e:\n",
    "#     #     print(f\"{e}\")\n",
    "#     #     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "97bfc56f-6c99-480c-9958-e2a71da416f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_python_code_prompt():\n",
    "    global execution_chain\n",
    "    # try:\n",
    "    map_process = extract_data_attributes(execution_chain)\n",
    "    cat_list = sum([d['categories_list'] for d in map_process['categories_match']],[])\n",
    "    cat_headers = ', '.join([d['table_header'] for d in map_process['categories_match'] if len(d['categories_list'])>0])\n",
    "    return f\"\"\"\n",
    "    You will be provided with a initial_table in a markdown format as << INITIAL_TABLE >>.\n",
    "    You will be provided with a template_table in a markdown format as << TEMPLATE_TABLE >>.\n",
    "    You will be provided with a JSON object with headers mapping as << HEADERS MAPPING >>>\n",
    "    You will be provided with a list of allowed categories as << CATEGORIES ALLOWED >>>\n",
    "\n",
    "    Create a python code for transforming the initial_table into template_table so initial_table will be indetical to template_table. Python Code must handle exceptions at each step: Python Code must end without errors.\n",
    "    \n",
    "    initial_table must be loaded from csv file as a dataframe of only strings using pandas 1.3.1. and python 3.9. change name to dataframe.\n",
    "    \n",
    "    template_table is only a markdown (is not a csv file) that only exists in this prompt as a guide.\n",
    "    \n",
    "    Headers must be renamed according to << HEADERS MAPPING >> \n",
    "    \n",
    "    All the rows of columns of renamed dataframe must look like than their columns in template_table: must have the same punctuation and letter cases\n",
    "    \n",
    "    Transform all the rows of columns (for serials) of renamed dataframe so they look like than their columns (for serials) in template_table.\n",
    "    \n",
    "    Transform the string columns with dates in dataframe to have the same date format than template_table. Consider the previous steps.\n",
    "    \n",
    "    Replace each value in the categories columns ({cat_headers}) with the most similar (difflib.get_close_matches()) item from the list in << CATEGORIES ALLOWED >>>. When calculate similarity, not use index [0] if difflib.get_close_matches() returns an empty list. In that case use the original category value. All resulting categories columns must be string columns. The python code needs to replace each value in the categorical columns of the renamed dataframe with the most similar item from list in the << CATEGORIES ALLOWED >>>. All categories must be kept as strings always.\n",
    "    \n",
    "    Only keep the same columns than template_table.\n",
    "\n",
    "    Save the dataframe as csv file called \"transformed_table\".\n",
    "\n",
    "    << INITIAL_TABLE >>\n",
    "    ```markdown\n",
    "    {json.dumps(map_process['initial_table'])}\n",
    "    ```\n",
    "\n",
    "    << TEMPLATE_TABLE >>\n",
    "    ```markdown\n",
    "    {json.dumps(map_process['final_table'])}\n",
    "    ```\n",
    "        \n",
    "    << HEADERS MAPPING >>\n",
    "    ```json\n",
    "    {json.dumps(map_process['header_match'])}\n",
    "    ```\n",
    "    \n",
    "    << CATEGORIES ALLOWED >>>\n",
    "    ```json\n",
    "    {json.dumps(cat_list)}\n",
    "    ```\n",
    "\n",
    "    << OUTPUT >>\n",
    "    You must return only a complete python script. Please avoid make extra comments, I need only the python script.\n",
    "\n",
    "    \"\"\"\n",
    "    # except Exception as e:\n",
    "    #     print(f\"{e}\")\n",
    "    #     return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb7075-af62-4ef0-87eb-b2811660a7a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Interface Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac2f494-a8b0-44d3-a13a-32e85bd37eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_html(md_table_string):\n",
    "    return markdown.markdown(md_table_string, extensions=['markdown.extensions.tables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e18425fa-deb0-4aee-96fb-3275c75b7121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_csv(file, file_label):\n",
    "    global _file_buffer\n",
    "    \n",
    "    # Read the uploaded CSV file with pandas\n",
    "    df = pd.read_csv(io.StringIO(file.decode('utf-8')))\n",
    "    \n",
    "    # Convert the DataFrame to an HTML table with added styles\n",
    "    html_table = df.to_html(classes='table table-striped')\n",
    "    \n",
    "    # Add CSS for scrollable table\n",
    "    styled_table = f\"\"\"\n",
    "    <div style=\"max-width: 100%; overflow-x: auto;\">\n",
    "        {html_table}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    _file_buffer[file_label] = df.to_markdown()\n",
    "    \n",
    "    return styled_table\n",
    "\n",
    "def process_template(file):\n",
    "    return process_csv(file, 'template')\n",
    "\n",
    "def process_new_file(file):\n",
    "    return process_csv(file, 'new_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f533c6cc-1922-45af-be7b-a23d2f6d429e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_file_buffer = {\n",
    "    'template':'',\n",
    "    'new_file':'',\n",
    "}\n",
    "execution_chain = None\n",
    "def tables_analysis():\n",
    "    global _file_buffer\n",
    "    global execution_chain\n",
    "    execution_chain = mapping_chain({\n",
    "        \"input_template\":_file_buffer['template'],\n",
    "        \"table_name\":\"new_file\",\n",
    "        \"input_file\":_file_buffer['new_file']\n",
    "    })\n",
    "    result_chain = json.loads(execution_chain['table_strings_match'])\n",
    "    show_table_html = markdown_to_html(result_chain['table'])\n",
    "    system_context = f\"\"\"\n",
    "This is the transformed data according to the template.\n",
    "\n",
    "Transformed Data:\n",
    "\n",
    "{result_chain['table']}\n",
    "\n",
    "Template:\n",
    "\n",
    "{execution_chain['input_template']}\n",
    "\n",
    "Input File:\n",
    "\n",
    "{execution_chain['input_file']}\n",
    "    \"\"\"\n",
    "    return show_table_html, system_context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c3a904-bbd0-4e5a-adfd-2efa461b0897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anaylisis_check = False\n",
    "def feedback_analysis(res):\n",
    "    global anaylisis_check\n",
    "    anaylisis_check = (res=='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b78da36-b132-4b5a-b520-3de7803b4963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_text = ''\n",
    "is_new_chat = True\n",
    "def generate_python_code():\n",
    "    global python_text\n",
    "    global is_new_chat\n",
    "    if anaylisis_check:\n",
    "        try:\n",
    "            del python_code_conv\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # No uses memory\n",
    "            python_code_conv = ConversationChain(\n",
    "                llm=llm, \n",
    "                verbose=False\n",
    "            )\n",
    "            python_text = python_code_conv.predict(input=get_python_code_prompt())\n",
    "            python_text = python_text.split('```python')[1].split('```')[0]\n",
    "            is_new_chat = True\n",
    "        except:\n",
    "            python_text = \"\"\n",
    "    else:\n",
    "        python_text = \"Please confirm the file was mapped correctly.\"\n",
    "    return python_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9beb5fe5-9add-4443-8411-54121c1898d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_code_check = False\n",
    "def feedback_python_code(res):\n",
    "    global anaylisis_check\n",
    "    global python_code_check\n",
    "    python_code_check = (res=='Yes')\n",
    "    if anaylisis_check:\n",
    "        if python_code_check:\n",
    "            return \"Python Code Valid!\"\n",
    "        else:\n",
    "            return \"Python Code Invalid!\"\n",
    "    else:\n",
    "        return \"Please confirm Analysis at Step 2.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59c4e857-1aa6-4244-94b0-6dfc40eb1a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_python_code():\n",
    "    global anaylisis_check\n",
    "    global python_code_check\n",
    "    global python_text\n",
    "    if (anaylisis_check & python_code_check):\n",
    "        # Save the string to a file\n",
    "        filename = \"output_python_code.py\"\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(python_text)\n",
    "\n",
    "        # Return the file path so Gradio can allow the user to download it\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5dc7ee-9f71-4a69-882f-36a67d164abb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chatbot functions\n",
    "There is a chatbot, here GPT memory handle the token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fb61bb0-2f0a-4803-872c-7c404790eef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=4000)\n",
    "bot_conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=False,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52f0d88b-f0a3-43c4-9de2-a68a55bdc9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def respond(message, chat_history, instruction, temperature=0.0):  \n",
    "    global is_new_chat\n",
    "    if is_new_chat:\n",
    "        memory.save_context({\"output\": python_text})\n",
    "        is_new_chat = False\n",
    "    else:\n",
    "        prompt = message\n",
    "    bot_message = bot_conversation.predict(input=message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5685d86e-7b96-426c-bfd1-7c2b586bfad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:5150\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:5150/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.HTML('<h1 align=\"center\">Test Task Submission</h1>')\n",
    "            gr.HTML('<h2 align=\"center\">Luis Bandres</h2>')\n",
    "            gr.HTML('<p align=\"center\">Add description here</p>')\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # Load Data\n",
    "            gr.HTML('<h2 align=\"center\">Step 1: Load Data</h2>')\n",
    "            \n",
    "            upload_template = gr.inputs.File(type=\"bytes\", label=\"Upload Template\")\n",
    "            data_template = gr.outputs.HTML(label=\"Template\")\n",
    "            upload_template.upload(process_template, inputs=upload_template, outputs=data_template)\n",
    "            \n",
    "            upload_file = gr.inputs.File(type=\"bytes\", label=\"Upload New File\")\n",
    "            data_file = gr.outputs.HTML(label=\"New File\")\n",
    "            upload_file.upload(process_new_file, inputs=upload_file, outputs=data_file)\n",
    "\n",
    "        with gr.Column():\n",
    "            # Analyse Data\n",
    "            gr.HTML('<h2 align=\"center\">Step 3: Transform using LLM </h2>')\n",
    "            gr.HTML('<h3 align=\"left\">Dont leave this page while processing.</h3>')\n",
    "            gr.HTML('<p align=\"left\">This process could take 5 minutes approximately...</p>')\n",
    "            btn_analyse = gr.Button(\"Transform Table\")\n",
    "            data_proposal = gr.outputs.HTML(label=\"Data Mapping Result\")\n",
    "            chk_analysis = gr.Radio([\"Yes\", \"No\"], label=\"Data was mapped correctly?\")\n",
    "\n",
    "            # Generating Code\n",
    "            gr.HTML('<h2 align=\"center\">Step 4: Generate Python Code </h2>')\n",
    "            btn_python_code = gr.Button(\"Generate\")\n",
    "            text_python_code = gr.Textbox(value=\"Please Generate Python Code\",label=\"Python Code\")\n",
    "            chk_python_code = gr.Radio([\"Yes\", \"No\"], label=\"Python code is correct?\")\n",
    "            \n",
    "            # Edit Code\n",
    "            gr.HTML('<h2 align=\"center\">Step 5: Download Python Code </h2>')\n",
    "            gr.HTML('<h3 align=\"left\">Requisites:</h3>')\n",
    "            gr.HTML('<p align=\"left\">   * Step 2 must be confirmed.</p>')\n",
    "            gr.HTML('<p align=\"left\">   * Step 3 must be confirmed.</p>')\n",
    "            python_code_result = gr.outputs.HTML(label=\"Result Python Code\")\n",
    "            btn_download_python = gr.Button(\"Save Code\")\n",
    "            download_python = gr.outputs.File(label=\"Generated Python Code\")\n",
    "    \n",
    "    with gr.Row():    \n",
    "        with gr.Column():\n",
    "            # Chatbot\n",
    "            gr.HTML('<h2 align=\"center\">Step 6: Advanced Options </h2>')\n",
    "            gr.HTML('<b align=\"left\">This is a chatbot powered by OpenAI GPT 3.5 so it can help you to editing the code with AI Assistance. The Table Analysis and the Generated Python Code have been loaded to this assistant.</p>')\n",
    "            chatbot = gr.Chatbot(height=446, label='Chatbot') #just to fit the notebook\n",
    "            msg = gr.Textbox(label=\"Prompt\")\n",
    "            with gr.Accordion(label=\"Settings\",open=False):\n",
    "                system_context = gr.Textbox(label=\"System Context\", lines=2, value=\"A conversation between a user and an LLM-based AI python coding assistant. The assistant gives helpful, honest, and precise answers. The assistant must act as a programmer.\")\n",
    "            btn = gr.Button(\"Submit\")\n",
    "            clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "            \n",
    "    # Actions\n",
    "    btn_analyse.click(tables_analysis, inputs=None, outputs=[data_proposal,system_context])\n",
    "    chk_analysis.change(feedback_analysis,inputs=chk_analysis, outputs=None)\n",
    "\n",
    "    btn_python_code.click(generate_python_code,inputs=None,outputs=text_python_code)\n",
    "    chk_python_code.change(feedback_python_code,inputs=chk_python_code, outputs=python_code_result)\n",
    "\n",
    "    btn_download_python.click(download_python_code,inputs=None,outputs=download_python)\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot, system_context], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot, system_context], outputs=[msg, chatbot]) #Press enter to submit\n",
    "\n",
    "gr.close_all()\n",
    "demo.queue().launch(share=False, server_port=int(os.environ['GRADIO_SERVER_PORT']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db6819-bb08-44ba-8352-509ed24ed59a",
   "metadata": {},
   "source": [
    "## Generating Examples for Further Training GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02ddef02-0982-4096-b266-63bc5001d366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08c22d1b-5c6d-4769-8ab3-cb1127883c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_task = '12'\n",
    "\n",
    "with open(f'./additional_task/training_data/sample_{number_task}.pickle', 'wb') as handle:\n",
    "    pickle.dump({\n",
    "        'prompt':get_python_code_prompt(),\n",
    "        'completion':python_text\n",
    "    }, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6bcac3c6-e99b-419a-9043-3948836c131d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'./additional_task/training_data/sample_{number_task}.pickle', 'rb') as handle:\n",
    "    bb = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c79c9458-9891-43d8-ac70-17b4058aa10e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You will be provided with a initial_table in a markdown format as << INITIAL_TABLE >>.\n",
      "    You will be provided with a template_table in a markdown format as << TEMPLATE_TABLE >>.\n",
      "    You will be provided with a JSON object with headers mapping as << HEADERS MAPPING >>>\n",
      "    You will be provided with a list of allowed categories as << CATEGORIES ALLOWED >>>\n",
      "\n",
      "    Create a python code for transforming the initial_table into template_table so initial_table will be indetical to template_table. Python Code must handle exceptions at each step: Python Code must end without errors.\n",
      "    \n",
      "    initial_table must be loaded from csv file as a dataframe of only strings using pandas 1.3.1. and python 3.9. change name to dataframe.\n",
      "    \n",
      "    template_table is only a markdown (is not a csv file) that only exists in this prompt as a guide.\n",
      "    \n",
      "    Headers must be renamed according to << HEADERS MAPPING >> \n",
      "    \n",
      "    All the rows of columns of renamed dataframe must look like than their columns in template_table: must have the same punctuation and letter cases\n",
      "    \n",
      "    Transform all the rows of columns (for serials) of renamed dataframe so they look like than their columns (for serials) in template_table.\n",
      "    \n",
      "    Transform the string columns with dates in dataframe to have the same date format than template_table. Consider the previous steps.\n",
      "    \n",
      "    Replace each value in the categories columns (Plan) with the most similar (difflib.get_close_matches()) item from the list in << CATEGORIES ALLOWED >>>. When calculate similarity, not use index [0] if difflib.get_close_matches() returns an empty list. In that case use the original category value. All resulting categories columns must be string columns. The python code needs to replace each value in the categorical columns of the renamed dataframe with the most similar item from list in the << CATEGORIES ALLOWED >>>. All categories must be kept as strings always.\n",
      "    \n",
      "    Only keep the same columns than template_table.\n",
      "\n",
      "    Save the dataframe as csv file called \"transformed_table\".\n",
      "\n",
      "    << INITIAL_TABLE >>\n",
      "    ```markdown\n",
      "    \"|    | Date-Policy   | Full_Name      | InsurancePlan   | Policy#   |   $Premium | Department   | Job_Title             | PolicyStart   | Full Name      | Insurance Type   | Policy#.1   |   Cost/Month |\\n|---:|:--------------|:---------------|:----------------|:----------|-----------:|:-------------|:----------------------|:--------------|:---------------|:-----------------|:------------|-------------:|\\n|  0 | 01/05/2023    | John Doe       | Gold Plan       | AB-12345  |        150 | IT           | Software Engineer     | 01/05/2023    | John Doe       | Gold             | AB-12345    |          150 |\\n|  1 | 01/06/2023    | Jane Smith     | Silver Plan     | CD-67890  |        100 | HR           | HR Manager            | 01/06/2023    | Jane Smith     | Silver           | CD-67890    |          100 |\\n|  2 | 01/07/2023    | Michael Brown  | Bronze Plan     | EF-10111  |         50 | Marketing    | Marketing Coordinator | 01/07/2023    | Michael Brown  | Bronze           | EF-10111    |           50 |\\n|  3 | 02/05/2023    | Alice Johnson  | Gold Plan       | GH-12121  |        150 | Finance      | Financial Analyst     | 02/05/2023    | Alice Johnson  | Gold             | GH-12121    |          150 |\\n|  4 | 02/06/2023    | Bob Wilson     | Silver Plan     | IJ-13131  |        100 | Sales        | Sales Executive       | 02/06/2023    | Bob Wilson     | Silver           | IJ-13131    |          100 |\\n|  5 | 02/07/2023    | Carol Martinez | Bronze Plan     | KL-14141  |         50 | Operations   | Operations Manager    | 02/07/2023    | Carol Martinez | Bronze           | KL-14141    |           50 |\\n|  6 | 03/05/2023    | David Anderson | Gold Plan       | MN-15151  |        150 | Legal        | Attorney              | 03/05/2023    | David Anderson | Gold             | MN-15151    |          150 |\\n|  7 | 03/06/2023    | Luis Bandres   | Gold Plan       | LB-19461  |        100 | IT           | AI Engineer           | 03/06/2023    | Luis Bandres   | Gold             | LB-19461    |          100 |\\n|  8 | 03/07/2023    | Eva Thomas     | Silver Plan     | OP-16161  |        100 | Product      | Product Manager       | 03/07/2023    | Eva Thomas     | Silver           | OP-16161    |          100 |\\n|  9 | 04/05/2023    | Frank Jackson  | Bronze Plan     | QR-17171  |         50 | Engineering  | Engineer              | 04/05/2023    | Frank Jackson  | Bronze           | QR-17171    |           50 |\\n| 10 | 04/06/2023    | Grace White    | Gold Plan       | ST-18181  |        150 | Design       | Graphic Designer      | 04/06/2023    | Grace White    | Gold             | ST-18181    |          150 |\"\n",
      "    ```\n",
      "\n",
      "    << TEMPLATE_TABLE >>\n",
      "    ```markdown\n",
      "    \"|    | Date         | EmployeeName   | Plan   | PolicyNumber   |   Premium |\\n|---:|:-------------|:---------------|:-------|:---------------|----------:|\\n|  0 | 01-05-2023   | John Doe       | Gold   | AB-12345       |       150 |\\n|  1 | 01-06-2023   | Jane Smith     | Silver | CD-67890       |       100 |\\n|  2 | 01-07-2023   | Michael Brown  | Bronze | EF-10111       |        50 |\\n|  3 | 02-05-2023   | Alice Johnson  | Gold   | GH-12121       |       150 |\\n|  4 | 02-06-2023   | Bob Wilson     | Silver | IJ-13131       |       100 |\\n|  5 | 02-07-2023   | Carol Martinez | Bronze | KL-14141       |        50 |\\n|  6 | 03-05-2023   | David Anderson | Gold   | MN-15151       |       150 |\\n|  7 | 03-06-2023   | Luis Bandres   | Gold   | LB-19461       |       100 |\\n|  8 | 03-07-2023   | Eva Thomas     | Silver | OP-16161       |       100 |\\n|  9 | 04-05-2023   | Frank Jackson  | Bronze | QR-17171       |        50 |\\n| 10 | 04-06-2023   | Grace White    | Gold   | ST-18181       |       150 |\"\n",
      "    ```\n",
      "        \n",
      "    << HEADERS MAPPING >>\n",
      "    ```json\n",
      "    [{\"table_header\": \"Date-Policy\", \"template_header\": \"Date\"}, {\"table_header\": \"Full_Name\", \"template_header\": \"EmployeeName\"}, {\"table_header\": \"InsurancePlan\", \"template_header\": \"Plan\"}, {\"table_header\": \"Policy#\", \"template_header\": \"PolicyNumber\"}, {\"table_header\": \"$Premium\", \"template_header\": \"Premium\"}]\n",
      "    ```\n",
      "    \n",
      "    << CATEGORIES ALLOWED >>>\n",
      "    ```json\n",
      "    [\"Gold\", \"Silver\", \"Bronze\"]\n",
      "    ```\n",
      "\n",
      "    << OUTPUT >>\n",
      "    You must return only a complete python script. Please avoid make extra comments, I need only the python script.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(bb['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e781bd47-2bb8-43bd-932a-07efd47df804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import pandas as pd\n",
      "import difflib\n",
      "\n",
      "# Load initial_table from csv file as a dataframe of only strings using pandas 1.3.1 and python 3.9\n",
      "dataframe = pd.read_csv('initial_table.csv', dtype=str)\n",
      "\n",
      "# Rename headers according to HEADERS MAPPING\n",
      "headers_mapping = [{\"table_header\": \"Date-Policy\", \"template_header\": \"Date\"}, {\"table_header\": \"Full_Name\", \"template_header\": \"EmployeeName\"}, {\"table_header\": \"InsurancePlan\", \"template_header\": \"Plan\"}, {\"table_header\": \"Policy#\", \"template_header\": \"PolicyNumber\"}, {\"table_header\": \"$Premium\", \"template_header\": \"Premium\"}]\n",
      "for mapping in headers_mapping:\n",
      "    dataframe.rename(columns={mapping['table_header']: mapping['template_header']}, inplace=True)\n",
      "\n",
      "# Transform rows of columns to match template_table\n",
      "for column in dataframe.columns:\n",
      "    if column.endswith('.1'):\n",
      "        template_column = column[:-2]\n",
      "        dataframe[template_column] = dataframe[column]\n",
      "        dataframe.drop(columns=[column], inplace=True)\n",
      "\n",
      "# Transform string columns with dates to have the same date format as template_table\n",
      "date_columns = ['Date', 'PolicyStart']\n",
      "for column in date_columns:\n",
      "    dataframe[column] = pd.to_datetime(dataframe[column]).dt.strftime('%d-%m-%Y')\n",
      "\n",
      "# Replace values in categories columns with the most similar item from CATEGORIES ALLOWED\n",
      "categories_allowed = [\"Gold\", \"Silver\", \"Bronze\"]\n",
      "categories_columns = ['Plan', 'Insurance Type']\n",
      "for column in categories_columns:\n",
      "    dataframe[column] = dataframe[column].apply(lambda x: difflib.get_close_matches(x, categories_allowed)[0] if difflib.get_close_matches(x, categories_allowed) else x)\n",
      "\n",
      "# Keep only the same columns as template_table\n",
      "template_columns = ['Date', 'EmployeeName', 'Plan', 'PolicyNumber', 'Premium']\n",
      "dataframe = dataframe[template_columns]\n",
      "\n",
      "# Save the dataframe as csv file called \"transformed_table\"\n",
      "dataframe.to_csv('transformed_table.csv', index=False)\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(bb['completion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deb224-8669-475b-b759-49dbf3d4acc6",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2d3b0-171a-4e23-ab91-8b1b6225c8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a314c5-5e37-4f48-ad3d-ccab7b21b2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
