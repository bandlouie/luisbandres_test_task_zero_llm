{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd71328-abaa-4768-8269-82c8a1b5ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import markdown\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import IPython.display\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb4ab6d-5c80-46aa-b493-91d4b294ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9886b95c-1f14-4a70-b1ea-5cb0200e2d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f469b2-52ba-4565-b9e6-173b0d9717ba",
   "metadata": {},
   "source": [
    "## LLM Chain\n",
    "\n",
    "It doesn't need history for completion. Therefore, is token-efficiente and it doesn't require the memory of GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2376ab46-b819-4e13-94ed-b656bb1ac67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_template_file_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You will be provided with a table in a markdown format as << INPUT >>.\n",
    "\n",
    "If there is not a markdown table in the input return an empty JSON object. Otherwise, return a JSON object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{\n",
    "    \"template_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column. If the input does not contain a header suggest a name for the column based on its data.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "            \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "            \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ descrption of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ]\n",
    "}}}}\n",
    "\n",
    "\n",
    "<< INPUT >>\n",
    "{input_template}\n",
    "\n",
    "<< OUTPUT >>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a66e69e-6636-4e2e-8fe4-abb09dcfbac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_file_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You will be provided with a table in a markdown format as << INPUT >>.\n",
    "Also you will provided with the name of the table as << TABLE >>\n",
    "\n",
    "If there is not a markdown table in the input return an empty JSON object. Otherwise, return a JSON object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it at the begining of the input.\n",
    "    \"file_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column. If the input does not contain a header suggest a name for the column based on its data.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"date_format\": string, \\ null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ description of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "    \"table\" : string \\ the complete markdown table in the input\n",
    "}}}}\n",
    "\n",
    "<< TABLE >>\n",
    "{table_name}\n",
    "\n",
    "<< INPUT >>\n",
    "{input_file}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b5e5ab3-39b1-47cb-8829-17dc9cb5828f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_header_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive two JSON Objects called table_info and template_description as inputs << INPUT >.\n",
    "\n",
    "Follow the following instruction:\n",
    "\n",
    "    Step 1: Go over the list table_info['file_metadata'] and find what is the N header in the list template_description['template_metadata'] most similar to the \"new_file\" table header.\n",
    "    Step 2: return the same \"table_info\" JSON object adding the following information:\n",
    "\n",
    "\"header_match\": [\n",
    "        {{{{\n",
    "            \"template_header\": string, \\ header of \"template\" table\n",
    "            \"table_header\": string, \\ header of \"new_file\" table table most similar to the N header of \"template\" table\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "\n",
    "\"template_header\" is the N header of \"template\" table most similar to the correspoding header of \"new_file\" table. Determine this similarity based only on the metadata such as:\n",
    "    * Data types\n",
    "    * Samples of both tables\n",
    "    * Description\n",
    "\n",
    "<< INPUT >>\n",
    "{table_info}\n",
    "{template_description}\n",
    "\n",
    "<< OUTPUT >>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e043046-b6c4-4347-842a-7d620a918a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_proposal_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive two JSON Objects called table_header_match and template_description as inputs << INPUT >.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "    \n",
    "    Step 1: Go over the list table_header_match[\"header_match\"].\n",
    "    Step 2: For each one of the table_header_match[\"header_match\"][\"table_header\"], replace the header of the markdown table in table_header_match[\"table\"] by table_header_match[\"header_match\"][\"template_header\"]\n",
    "    Step 3: The new markdown table must have only the columns in listed in table_header_match[\"header_match\"][\"template_header\"]. Remove all the remaining columns different to table_header_match[\"header_match\"][\"template_header\"].\n",
    "\n",
    "Return the new markdown table in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_header_match[\"table_name\"].\n",
    "    \"file_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "            \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "            \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ descrption of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "    \"modified_table\" : string, \\ the new markdown table.\n",
    "    \"template_metadata\": template_description[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_header_match}\n",
    "{template_description}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78000db-e16d-4dfa-836b-2e17203b1c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_categories_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called simple_table as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to find the column in the \"modified_table\" that is most similar to the N header in the \"template_metadata\" list. Then, select only the categorical columns and return the \"simple_table\" JSON object with the added information.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: compare the headers in the \"modified_table\" with the headers in the \"template_metadata\" list. We will  iterate over the columns in the \"modified_table\" and find the column that is most similar to the N header in the \"template_metadata\" list.\n",
    "Step 2: After finding the most similar column, check if it is a categorical column by checking the \"categorical\" key in the \"file_metadata\" list.\n",
    "Step 3: Add the following information to the \"simple_table\" JSON object.\n",
    "Step 4: Return the updated  \"simple_table\" JSON object.\n",
    "\n",
    "\"categories_match\": [\n",
    "    {{{{\n",
    "        \"categories_list\": string, \\ list of categories in simple_table['template_metadata']\n",
    "        \"table_header\": string, \\ header of markdown table in simple_table[\"modified_table\"] most similar to the N header of \"template_metadata\"\n",
    "    }}}},\n",
    "    ...\n",
    "],\n",
    "\n",
    "<< INPUT >>\n",
    "{simple_table}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return the updated  \"simple_table\" JSON object.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc4766f-7d4a-4b96-90c5-178313553147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories_result_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_categories_match as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to generate a markdown table by replacing each value in the categorical columns of the \"modified_table\" with the most similar item from the \"categories_list\" in the \"categories_match\" section. The updated table should be returned as a JSON object.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: Iterate over each categorical column in the \"modified_table\".\n",
    "Step 2: Replace each value in the column with the most similar item from the \"categories_list\" in the \"categories_match\" section.\n",
    "Setp 3: the new markdown table will be called correct_cats_markdown_table\n",
    "\n",
    "Return the new markdown table (correct_cats_markdown_table) in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_categories_match[\"table_name\"].\n",
    "    \"file_metadata\": [\n",
    "    {{{{\n",
    "        \"header\": string, \\ name of the column.\n",
    "        \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "        \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "        \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "        \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "        \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "        \"description\": string \\ descrption of this column based only on its data.\n",
    "    }}}},\n",
    "    ...\n",
    "    ],\n",
    "    \"table\" : string, \\ the new markdown table (correct_cats_markdown_table).\n",
    "    \"template_metadata\": table_categories_match[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_categories_match}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return only the JSON Object\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1c545e-ae06-48fc-967f-99f5b998004b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_dates_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_categories_result as input << INPUT >.\n",
    "\n",
    "Change the format of each one the rows of date columns in the markdown in table_categories_result[\"table\"] according to the date format in the list table_categories_result[\"template_metadata\"]\n",
    "\n",
    "The new markdown table will be called correct_dates_markdown_table\n",
    "\n",
    "Return the new markdown table (correct_dates_markdown_table) in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_categories_result[\"table_name\"].\n",
    "    \"table\" : string, \\ the new markdown table (correct_dates_markdown_table).\n",
    "    \"template_metadata\": table_categories_result[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_categories_result}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return only the JSON Object\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5eae172-ad8b-48dd-b874-916a2bc0948b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_strings_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_dates_result as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to find the column in the markdown \"table\" that is most similar to the N header in the \"template_metadata\" list. Then, select only the string columns and return the \"table_dates_result\" JSON object with the added information.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: compare the headers in the \"table\" with the headers in the \"template_metadata\" list. We will  iterate over the columns in the \"table\" and find the column that is most similar to the N header in the \"template_metadata\" list.\n",
    "Step 2: After finding the most similar column, check if it is a string column by checking the \"type\" key in the \"file_metadata\" list.\n",
    "Step 3: Ignore if it is a categorical, numerical or date column by checking the \"categorical\" key in the \"file_metadata\" list.\n",
    "Step 4: Add the following information to the \"table_dates_result\" JSON object.\n",
    "Step 5: Return the updated  \"table_dates_result\" JSON object.\n",
    "\n",
    "\"strings_match\": [\n",
    "    {{{{\n",
    "        \"selected_sample\": string, \\ sample of data in table_dates_result[\"template_metadata\"]\n",
    "        \"table_header\": string, \\ header of markdown table in table_dates_result[\"table\"] most similar to the N header of \"template_metadata\"\n",
    "    }}}},\n",
    "    ...\n",
    "],\n",
    "\n",
    "<< INPUT >>\n",
    "{table_dates_result}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return the updated \"table_dates_result\" JSON object.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad655a7-5623-47d2-a44f-0dc1c0dcefce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_template_load = LLMChain(llm=llm, prompt=load_template_file_prompt, \n",
    "                     output_key=\"template_description\"\n",
    "                    )\n",
    "chain_load = LLMChain(llm=llm, prompt=load_file_prompt, \n",
    "                     output_key=\"table_info\"\n",
    "                    )\n",
    "chain_header_formatting = LLMChain(llm=llm, prompt=formating_header_prompt, \n",
    "                     output_key=\"table_header_match\"\n",
    "                    )\n",
    "chain_proposal = LLMChain(llm=llm, prompt=table_proposal_prompt, \n",
    "                     output_key=\"simple_table\"\n",
    "                    )\n",
    "chain_cats_formatting = LLMChain(llm=llm, prompt=formating_categories_prompt, \n",
    "                     output_key=\"table_categories_match\"\n",
    "                    )\n",
    "chain_cats_result = LLMChain(llm=llm, prompt=categories_result_prompt, \n",
    "                     output_key=\"table_categories_result\"\n",
    "                    )\n",
    "chain_dates_result = LLMChain(llm=llm, prompt=formating_dates_prompt, \n",
    "                     output_key=\"table_dates_result\"\n",
    "                    )\n",
    "chain_strings_formatting = LLMChain(llm=llm, prompt=formating_strings_prompt, \n",
    "                     output_key=\"table_strings_match\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118147fe-30ab-40d3-8f5c-898d25bc481d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_template_load, chain_load, chain_header_formatting, chain_proposal, chain_cats_formatting, chain_cats_result, chain_dates_result, chain_strings_formatting],\n",
    "    input_variables=[\"input_template\",\"table_name\",\"input_file\"],\n",
    "    output_variables=[\"table_header_match\",\"table_categories_match\",\"table_strings_match\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03cafe2-4edd-4e91-8210-d6d907abff59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Interface\n",
    "\n",
    "There is a chatbot, here GPT memory handle the token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb61bb0-2f0a-4803-872c-7c404790eef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=False,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac2f494-a8b0-44d3-a13a-32e85bd37eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_html(md_table_string):\n",
    "    return markdown.markdown(md_table_string, extensions=['markdown.extensions.tables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e18425fa-deb0-4aee-96fb-3275c75b7121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_csv(file, file_label):\n",
    "    global _file_buffer\n",
    "    \n",
    "    # Read the uploaded CSV file with pandas\n",
    "    df = pd.read_csv(io.StringIO(file.decode('utf-8')))\n",
    "    \n",
    "    # Convert the DataFrame to an HTML table with added styles\n",
    "    html_table = df.to_html(classes='table table-striped')\n",
    "    \n",
    "    # Add CSS for scrollable table\n",
    "    styled_table = f\"\"\"\n",
    "    <div style=\"max-width: 100%; overflow-x: auto;\">\n",
    "        {html_table}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    _file_buffer[file_label] = df.to_markdown()\n",
    "    \n",
    "    return styled_table\n",
    "\n",
    "def process_template(file):\n",
    "    return process_csv(file, 'template')\n",
    "\n",
    "def process_new_file(file):\n",
    "    return process_csv(file, 'new_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7724622e-d629-40ab-95e9-93b169f8c36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_chat_prompt(message, chat_history, instruction):\n",
    "    prompt = f\"System Context:{instruction}\"\n",
    "    # for turn in chat_history:\n",
    "    #     user_message, bot_message = turn\n",
    "    #     prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    # prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f0d88b-f0a3-43c4-9de2-a68a55bdc9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def respond(message, chat_history, instruction, temperature=0.7):\n",
    "    formatted_prompt = format_chat_prompt(message, chat_history, instruction)\n",
    "    bot_message = conversation.predict(input=formatted_prompt)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f533c6cc-1922-45af-be7b-a23d2f6d429e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tables_analysis():\n",
    "    global _file_buffer\n",
    "    execution_chain = overall_chain({\n",
    "        \"input_template\":_file_buffer['template'],\n",
    "        \"table_name\":\"new_file\",\n",
    "        \"input_file\":_file_buffer['new_file']\n",
    "    })\n",
    "    result_chain = json.loads(execution_chain['table_strings_match'])\n",
    "    show_table_html = markdown_to_html(result_chain['table'])\n",
    "    system_context = f\"\"\"\n",
    "This is the transformed data according to the template.\n",
    "\n",
    "Transformed Data:\n",
    "\n",
    "{result_chain['table']}\n",
    "\n",
    "Template:\n",
    "\n",
    "{execution_chain['input_template']}\n",
    "\n",
    "Input File:\n",
    "\n",
    "{execution_chain['input_file']}\n",
    "    \"\"\"\n",
    "    return show_table_html, system_context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d27984-9304-43e6-8ed9-e8ec6ad40836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_file_buffer = {\n",
    "    'template':'',\n",
    "    'new_file':'',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5685d86e-7b96-426c-bfd1-7c2b586bfad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:5150\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:5150/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Row():\n",
    "    \n",
    "        with gr.Column():\n",
    "            # Load Data\n",
    "            gr.HTML('<h1 align=\"center\">Step 1: Load Data</h1>')\n",
    "            \n",
    "            upload_template = gr.inputs.File(type=\"bytes\", label=\"Upload Template\")\n",
    "            data_template = gr.outputs.HTML(label=\"Template\")\n",
    "            upload_template.upload(process_template, inputs=upload_template, outputs=data_template)\n",
    "            \n",
    "            upload_file = gr.inputs.File(type=\"bytes\", label=\"Upload New File\")\n",
    "            data_file = gr.outputs.HTML(label=\"New File\")\n",
    "            upload_file.upload(process_new_file, inputs=upload_file, outputs=data_file)\n",
    "\n",
    "        with gr.Column():\n",
    "            # Analyse Data\n",
    "            gr.HTML('<h1 align=\"center\">Step 2: Analysis </h1>')\n",
    "            gr.HTML('<h2 align=\"left\">Analysis of Table</h2>')\n",
    "            gr.HTML('<h3 align=\"left\">This process could take up to 5 minutes.</h3>')\n",
    "            btn_analyse = gr.Button(\"Analyse Table\")\n",
    "            data_proposal = gr.outputs.HTML(label=\"Proposal\")\n",
    "            \n",
    "            # Chatbot\n",
    "            gr.HTML('<h1 align=\"center\">Step 3: Chatbot </h1>')\n",
    "            chatbot = gr.Chatbot(height=446, label='Chatbot') #just to fit the notebook\n",
    "            msg = gr.Textbox(label=\"Prompt\")\n",
    "            with gr.Accordion(label=\"Advanced options\",open=False):\n",
    "                system_context = gr.Textbox(label=\"System Context\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
    "                temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "            btn = gr.Button(\"Submit\")\n",
    "            clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "            \n",
    "            # Actions\n",
    "            btn_analyse.click(tables_analysis, inputs=None, outputs=[data_proposal,system_context])\n",
    "            btn.click(respond, inputs=[msg, chatbot, system_context], outputs=[msg, chatbot])\n",
    "            msg.submit(respond, inputs=[msg, chatbot, system_context], outputs=[msg, chatbot]) #Press enter to submit\n",
    "\n",
    "gr.close_all()\n",
    "demo.queue().launch(share=False, server_port=int(os.environ['GRADIO_SERVER_PORT']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0a903-1efe-453a-a84c-20bd691169cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
