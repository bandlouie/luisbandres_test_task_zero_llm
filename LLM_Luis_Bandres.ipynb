{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd71328-abaa-4768-8269-82c8a1b5ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import markdown\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import IPython.display\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4ab6d-5c80-46aa-b493-91d4b294ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886b95c-1f14-4a70-b1ea-5cb0200e2d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f469b2-52ba-4565-b9e6-173b0d9717ba",
   "metadata": {},
   "source": [
    "## LLM Mapping Chain\n",
    "\n",
    "It doesn't need history for completion. Therefore, is token-efficiente and it doesn't require the memory of GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376ab46-b819-4e13-94ed-b656bb1ac67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_template_file_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You will be provided with a table in a markdown format as << INPUT >>.\n",
    "\n",
    "If there is not a markdown table in the input return an empty JSON object. Otherwise, return a JSON object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{\n",
    "    \"template_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column. If the input does not contain a header suggest a name for the column based on its data.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "            \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "            \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ descrption of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ]\n",
    "}}}}\n",
    "\n",
    "\n",
    "<< INPUT >>\n",
    "{input_template}\n",
    "\n",
    "<< OUTPUT >>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66e69e-6636-4e2e-8fe4-abb09dcfbac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_file_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You will be provided with a table in a markdown format as << INPUT >>.\n",
    "Also you will provided with the name of the table as << TABLE >>\n",
    "\n",
    "If there is not a markdown table in the input return an empty JSON object. Otherwise, return a JSON object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it at the begining of the input.\n",
    "    \"file_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column. If the input does not contain a header suggest a name for the column based on its data.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"date_format\": string, \\ null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ description of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "    \"table\" : string \\ the complete markdown table in the input\n",
    "}}}}\n",
    "\n",
    "<< TABLE >>\n",
    "{table_name}\n",
    "\n",
    "<< INPUT >>\n",
    "{input_file}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e5ab3-39b1-47cb-8829-17dc9cb5828f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_header_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive two JSON Objects called table_info and template_description as inputs << INPUT >.\n",
    "\n",
    "Follow the following instruction:\n",
    "\n",
    "    Step 1: Go over the list table_info['file_metadata'] and find what is the N header in the list template_description['template_metadata'] most similar to the \"new_file\" table header.\n",
    "    Step 2: return the same \"table_info\" JSON object adding the following information:\n",
    "\n",
    "\"header_match\": [\n",
    "        {{{{\n",
    "            \"template_header\": string, \\ header of \"template\" table\n",
    "            \"table_header\": string, \\ header of \"new_file\" table table most similar to the N header of \"template\" table\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "\n",
    "\"template_header\" is the N header of \"template\" table most similar to the correspoding header of \"new_file\" table. Determine this similarity based only on the metadata such as:\n",
    "    * Data types\n",
    "    * Samples of both tables\n",
    "    * Description\n",
    "\n",
    "<< INPUT >>\n",
    "{table_info}\n",
    "{template_description}\n",
    "\n",
    "<< OUTPUT >>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e043046-b6c4-4347-842a-7d620a918a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_proposal_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive two JSON Objects called table_header_match and template_description as inputs << INPUT >.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "    \n",
    "    Step 1: Go over the list table_header_match[\"header_match\"].\n",
    "    Step 2: For each one of the table_header_match[\"header_match\"][\"table_header\"], replace the header of the markdown table in table_header_match[\"table\"] by table_header_match[\"header_match\"][\"template_header\"]\n",
    "    Step 3: The new markdown table must have only the columns in listed in table_header_match[\"header_match\"][\"template_header\"]. Remove all the remaining columns different to table_header_match[\"header_match\"][\"template_header\"].\n",
    "\n",
    "Return the new markdown table in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_header_match[\"table_name\"].\n",
    "    \"file_metadata\": [\n",
    "        {{{{\n",
    "            \"header\": string, \\ name of the column.\n",
    "            \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "            \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "            \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "            \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "            \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "            \"description\": string \\ descrption of this column based only on its data.\n",
    "        }}}},\n",
    "        ...\n",
    "    ],\n",
    "    \"modified_table\" : string, \\ the new markdown table.\n",
    "    \"template_metadata\": template_description[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_header_match}\n",
    "{template_description}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78000db-e16d-4dfa-836b-2e17203b1c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_categories_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called simple_table as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to find the column in the \"modified_table\" that is most similar to the N header in the \"template_metadata\" list. Then, select only the categorical columns and return the \"simple_table\" JSON object with the added information.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: compare the headers in the \"modified_table\" with the headers in the \"template_metadata\" list. We will  iterate over the columns in the \"modified_table\" and find the column that is most similar to the N header in the \"template_metadata\" list.\n",
    "Step 2: After finding the most similar column, check if it is a categorical column by checking the \"categorical\" key in the \"file_metadata\" list.\n",
    "Step 3: Add the following information to the \"simple_table\" JSON object.\n",
    "Step 4: Return the updated  \"simple_table\" JSON object.\n",
    "\n",
    "\"categories_match\": [\n",
    "    {{{{\n",
    "        \"categories_list\": string, \\ list of categories in simple_table['template_metadata']\n",
    "        \"table_header\": string, \\ header of markdown table in simple_table[\"modified_table\"] most similar to the N header of \"template_metadata\"\n",
    "    }}}},\n",
    "    ...\n",
    "],\n",
    "\n",
    "<< INPUT >>\n",
    "{simple_table}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return the updated  \"simple_table\" JSON object.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4766f-7d4a-4b96-90c5-178313553147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories_result_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_categories_match as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to generate a markdown table by replacing each value in the categorical columns of the \"modified_table\" with the most similar item from the \"categories_list\" in the \"categories_match\" section. The updated table should be returned as a JSON object.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: Iterate over each categorical column in the \"modified_table\".\n",
    "Step 2: Replace each value in the column with the most similar item from the \"categories_list\" in the \"categories_match\" section.\n",
    "Setp 3: the new markdown table will be called correct_cats_markdown_table\n",
    "\n",
    "Return the new markdown table (correct_cats_markdown_table) in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_categories_match[\"table_name\"].\n",
    "    \"file_metadata\": [\n",
    "    {{{{\n",
    "        \"header\": string, \\ name of the column.\n",
    "        \"type\": string, \\ type of the data column of the markdown file in the input. \n",
    "        \"sample\": \\ put a not null samble of the column. This sample should have the most common value which is not null.\n",
    "        \"categorical\": bool \\ check if the column is categorical (true) or not categorical (false).\n",
    "        \"categories_list\": [] \\ list of the unique values if the column is categorical.\n",
    "        \"date_format\": null except if type is date suggest SQL DATE FORMAT for converting the column values to date.\n",
    "        \"description\": string \\ descrption of this column based only on its data.\n",
    "    }}}},\n",
    "    ...\n",
    "    ],\n",
    "    \"table\" : string, \\ the new markdown table (correct_cats_markdown_table).\n",
    "    \"template_metadata\": table_categories_match[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_categories_match}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return only the JSON Object\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c545e-ae06-48fc-967f-99f5b998004b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_dates_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_categories_result as input << INPUT >.\n",
    "\n",
    "Change the format of each one the rows of date columns in the markdown in table_categories_result[\"table\"] according to the date format in the list table_categories_result[\"template_metadata\"]\n",
    "\n",
    "The new markdown table will be called correct_dates_markdown_table\n",
    "\n",
    "Return the new markdown table (correct_dates_markdown_table) in a JSON Object formatted to look like:\n",
    "\n",
    "<< FORMATTING >>\n",
    "{{{{ \n",
    "    \"table_name\": string, \\ name of the table. you can find it in table_categories_result[\"table_name\"].\n",
    "    \"table\" : string, \\ the new markdown table (correct_dates_markdown_table).\n",
    "    \"template_metadata\": table_categories_result[\"template_metadata\"]  \\ the template metadata.\n",
    "}}}}\n",
    "\n",
    "<< INPUT >>\n",
    "{table_categories_result}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return only the JSON Object\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eae172-ad8b-48dd-b874-916a2bc0948b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formating_strings_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You will receive a JSON Object called table_dates_result as input << INPUT >.\n",
    "\n",
    "Based on the given input, the task is to find the column in the markdown \"table\" that is most similar to the N header in the \"template_metadata\" list. Then, select only the string columns and return the \"table_dates_result\" JSON object with the added information.\n",
    "\n",
    "Follow the next instructions for generating a markdown table:\n",
    "Step 1: compare the headers in the \"table\" with the headers in the \"template_metadata\" list. We will  iterate over the columns in the \"table\" and find the column that is most similar to the N header in the \"template_metadata\" list.\n",
    "Step 2: After finding the most similar column, check if it is a string column by checking the \"type\" key in the \"file_metadata\" list.\n",
    "Step 3: Ignore if it is a categorical, numerical or date column by checking the \"categorical\" key in the \"file_metadata\" list.\n",
    "Step 4: Add the following information to the \"table_dates_result\" JSON object.\n",
    "Step 5: Return the updated  \"table_dates_result\" JSON object.\n",
    "\n",
    "\"strings_match\": [\n",
    "    {{{{\n",
    "        \"selected_sample\": string, \\ sample of data in table_dates_result[\"template_metadata\"]\n",
    "        \"table_header\": string, \\ header of markdown table in table_dates_result[\"table\"] most similar to the N header of \"template_metadata\"\n",
    "    }}}},\n",
    "    ...\n",
    "],\n",
    "\n",
    "<< INPUT >>\n",
    "{table_dates_result}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Return the updated \"table_dates_result\" JSON object.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad655a7-5623-47d2-a44f-0dc1c0dcefce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_template_load = LLMChain(llm=llm, prompt=load_template_file_prompt, \n",
    "                     output_key=\"template_description\"\n",
    "                    )\n",
    "chain_load = LLMChain(llm=llm, prompt=load_file_prompt, \n",
    "                     output_key=\"table_info\"\n",
    "                    )\n",
    "chain_header_formatting = LLMChain(llm=llm, prompt=formating_header_prompt, \n",
    "                     output_key=\"table_header_match\"\n",
    "                    )\n",
    "chain_proposal = LLMChain(llm=llm, prompt=table_proposal_prompt, \n",
    "                     output_key=\"simple_table\"\n",
    "                    )\n",
    "chain_cats_formatting = LLMChain(llm=llm, prompt=formating_categories_prompt, \n",
    "                     output_key=\"table_categories_match\"\n",
    "                    )\n",
    "chain_cats_result = LLMChain(llm=llm, prompt=categories_result_prompt, \n",
    "                     output_key=\"table_categories_result\"\n",
    "                    )\n",
    "chain_dates_result = LLMChain(llm=llm, prompt=formating_dates_prompt, \n",
    "                     output_key=\"table_dates_result\"\n",
    "                    )\n",
    "chain_strings_formatting = LLMChain(llm=llm, prompt=formating_strings_prompt, \n",
    "                     output_key=\"table_strings_match\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118147fe-30ab-40d3-8f5c-898d25bc481d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_chain = SequentialChain(\n",
    "    chains=[chain_template_load, chain_load, chain_header_formatting, chain_proposal, chain_cats_formatting, chain_cats_result, chain_dates_result, chain_strings_formatting],\n",
    "    input_variables=[\"input_template\",\"table_name\",\"input_file\"],\n",
    "    output_variables=[\"table_header_match\",\"table_categories_match\",\"table_strings_match\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8edb3-de6f-4a82-b550-e9c4c8ac6a7f",
   "metadata": {},
   "source": [
    "## LLM Coding Chain\n",
    "\n",
    "It doesn't need history for completion. Therefore, is token-efficiente and it doesn't require the memory of GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddecb26-abe6-4f97-856e-450b8504ddac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_data_attributes(analysis_chain):\n",
    "    return dict(\n",
    "        # Inputs\n",
    "        template_table = analysis_chain['input_template'],\n",
    "        initial_table = analysis_chain['input_file'],\n",
    "        # Metadata\n",
    "        file_metadata = json.loads(analysis_chain['table_header_match'])['file_metadata'],\n",
    "        template_metadata = json.loads(analysis_chain['table_categories_match'])['template_metadata'],\n",
    "        # Feature Mappings\n",
    "        header_match = json.loads(analysis_chain['table_header_match'])['header_match'],\n",
    "        categories_match = json.loads(analysis_chain['table_categories_match'])['categories_match'],\n",
    "        strings_match = json.loads(analysis_chain['table_strings_match'])['strings_match'],\n",
    "        # Final Table\n",
    "        final_table = json.loads(analysis_chain['table_strings_match'])['table']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e9dc9-d675-45a0-908a-8c0019dd15d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_python_code_prompt():\n",
    "    global execution_chain\n",
    "    try:\n",
    "        map_process = extract_data_attributes(execution_chain)\n",
    "        return f\"\"\"\n",
    "        Also, you will be provided with a initial_table in a markdown format as << INITIAL_TABLE >>. You need to transform the initial_table to the same format than  template table.\n",
    "        Finally, you will be provided with a final_table in a markdown format as << FINAL_TABLE >>. The final_table is the expected result you need to achieve.\n",
    "\n",
    "        The objective is to create a python code for transforming the initial_table into final_table. You need to use the mapping from renaming columns of initial_table to making their headers the same than final_table.\n",
    "\n",
    "\n",
    "\n",
    "        Please follow the steps for creating a python code:\n",
    "\n",
    "        STEP 1: Read initial_table using pandas as a dataframe.\n",
    "\n",
    "        STEP 2: Rename columns using HEADERS MAPPING.\n",
    "        << HEADERS MAPPING >>\n",
    "        ```json\n",
    "        {json.dumps(map_process['header_match'])}\n",
    "        ```\n",
    "        \n",
    "        STEP 3: In the following steps only consider the new headers of the columns assigned in STEP 2. Also discard other columns.\n",
    "        \n",
    "        STEP 4: Transform the date columns of inital_table to the same date format than final_table. Considers the previous steps.\n",
    "\n",
    "        STEP 5: Replace each value in the column with the most similar item from the \"categories_list\" << CATEGORIES REQUIRED >>>. The python code needs to replace each value in the categorical columns of the dataframe with the most similar item from the \"categories_list\" in the << CATEGORIES REQUIRED >>>.\n",
    "        << CATEGORIES REQUIRED >>>\n",
    "        ```json\n",
    "        {json.dumps(map_process['categories_match'])}\n",
    "        ```\n",
    "        You need to implement in this step a code for calculating similarities between strings. Considers the previous steps.\n",
    "\n",
    "        STEP 6: Transform all the rows of string columns of dataframe so they have the same format than their corresponding columns in final table. Be sure that values in dataframe string columns have the same punctuation and spaces than their corresponding columns in final_table. For this use regex. Considers the previous steps.\n",
    "\n",
    "        STEP 7: Transform values in numeric columns of inital_table have the same decimals separators and decimals quantity than their corresponding numeric columns in final_table. Considers the previous steps.\n",
    "\n",
    "        STEP 8: Read all the code and be sure that all required libraries in the code are correctly imported. Considers the previous steps.\n",
    "        \n",
    "        STEP 9: Save the dataframe as csv file called \"transformed_table\".\n",
    "        \n",
    "        Remember the objective is to reproduce the final_table using python 3.9 or above.\n",
    "        \n",
    "        CONSTRAINTS\n",
    "        a) Code will receive only initial_table as a csv file.\n",
    "        B) Avoid inplae parameters in pandas transformations\n",
    "        c) The code need to save the transformed table as csv.\n",
    "        d) Categorical columns must be filled (not completely empty).\n",
    "        d) you need to test that produced result table is exactly the same than final_table provided.\n",
    "        e) You must return only a complete python script.\n",
    "\n",
    "        << INITIAL_TABLE >>\n",
    "        {json.dumps(map_process['initial_table'])}\n",
    "\n",
    "        << FINAL_TABLE >>\n",
    "        {json.dumps(map_process['final_table'])}\n",
    "\n",
    "        << OUTPUT >>\n",
    "        You must return only a complete python script. Please avoid make extra comments, I need only the python script.\n",
    "\n",
    "        \"\"\"\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb7075-af62-4ef0-87eb-b2811660a7a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Interface Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac2f494-a8b0-44d3-a13a-32e85bd37eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_html(md_table_string):\n",
    "    return markdown.markdown(md_table_string, extensions=['markdown.extensions.tables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18425fa-deb0-4aee-96fb-3275c75b7121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_csv(file, file_label):\n",
    "    global _file_buffer\n",
    "    \n",
    "    # Read the uploaded CSV file with pandas\n",
    "    df = pd.read_csv(io.StringIO(file.decode('utf-8')))\n",
    "    \n",
    "    # Convert the DataFrame to an HTML table with added styles\n",
    "    html_table = df.to_html(classes='table table-striped')\n",
    "    \n",
    "    # Add CSS for scrollable table\n",
    "    styled_table = f\"\"\"\n",
    "    <div style=\"max-width: 100%; overflow-x: auto;\">\n",
    "        {html_table}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    _file_buffer[file_label] = df.to_markdown()\n",
    "    \n",
    "    return styled_table\n",
    "\n",
    "def process_template(file):\n",
    "    return process_csv(file, 'template')\n",
    "\n",
    "def process_new_file(file):\n",
    "    return process_csv(file, 'new_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533c6cc-1922-45af-be7b-a23d2f6d429e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_file_buffer = {\n",
    "    'template':'',\n",
    "    'new_file':'',\n",
    "}\n",
    "execution_chain = None\n",
    "def tables_analysis():\n",
    "    global _file_buffer\n",
    "    global execution_chain\n",
    "    execution_chain = mapping_chain({\n",
    "        \"input_template\":_file_buffer['template'],\n",
    "        \"table_name\":\"new_file\",\n",
    "        \"input_file\":_file_buffer['new_file']\n",
    "    })\n",
    "    result_chain = json.loads(execution_chain['table_strings_match'])\n",
    "    show_table_html = markdown_to_html(result_chain['table'])\n",
    "    system_context = f\"\"\"\n",
    "This is the transformed data according to the template.\n",
    "\n",
    "Transformed Data:\n",
    "\n",
    "{result_chain['table']}\n",
    "\n",
    "Template:\n",
    "\n",
    "{execution_chain['input_template']}\n",
    "\n",
    "Input File:\n",
    "\n",
    "{execution_chain['input_file']}\n",
    "    \"\"\"\n",
    "    return show_table_html, system_context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3a904-bbd0-4e5a-adfd-2efa461b0897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anaylisis_check = False\n",
    "def feedback_analysis(res):\n",
    "    global anaylisis_check\n",
    "    anaylisis_check = (res=='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78da36-b132-4b5a-b520-3de7803b4963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_text = ''\n",
    "is_new_chat = True\n",
    "def generate_python_code():\n",
    "    global python_text\n",
    "    global is_new_chat\n",
    "    if anaylisis_check:\n",
    "        try:\n",
    "            del python_code_conv\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # No uses memory\n",
    "            python_code_conv = ConversationChain(\n",
    "                llm=llm, \n",
    "                verbose=False\n",
    "            )\n",
    "            python_text = python_code_conv.predict(input=get_python_code_prompt())\n",
    "            python_text = python_text.split('```python')[1].split('```')[0]\n",
    "            is_new_chat = True\n",
    "        except:\n",
    "            python_text = \"\"\n",
    "    else:\n",
    "        python_text = \"Please confirm the file was mapped correctly.\"\n",
    "    return python_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb5fe5-9add-4443-8411-54121c1898d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_code_check = False\n",
    "def feedback_python_code(res):\n",
    "    global anaylisis_check\n",
    "    global python_code_check\n",
    "    python_code_check = (res=='Yes')\n",
    "    if anaylisis_check:\n",
    "        if python_code_check:\n",
    "            return \"Python Code Valid!\"\n",
    "        else:\n",
    "            return \"Python Code Invalid!\"\n",
    "    else:\n",
    "        return \"Please confirm Analysis at Step 2.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4e857-1aa6-4244-94b0-6dfc40eb1a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_python_code():\n",
    "    global anaylisis_check\n",
    "    global python_code_check\n",
    "    global python_text\n",
    "    if (anaylisis_check & python_code_check):\n",
    "        # Save the string to a file\n",
    "        filename = \"output_python_code.py\"\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(python_text)\n",
    "\n",
    "        # Return the file path so Gradio can allow the user to download it\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5dc7ee-9f71-4a69-882f-36a67d164abb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chatbot functions\n",
    "There is a chatbot, here GPT memory handle the token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb61bb0-2f0a-4803-872c-7c404790eef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=4000)\n",
    "bot_conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=False,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0d88b-f0a3-43c4-9de2-a68a55bdc9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def respond(message, chat_history, instruction, temperature=0.0):  \n",
    "    global is_new_chat\n",
    "    if is_new_chat:\n",
    "        memory.save_context({\"output\": python_text})\n",
    "        is_new_chat = False\n",
    "    else:\n",
    "        prompt = message\n",
    "    bot_message = bot_conversation.predict(input=message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685d86e-7b96-426c-bfd1-7c2b586bfad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.HTML('<h1 align=\"center\">Test Task Submission</h1>')\n",
    "            gr.HTML('<h2 align=\"center\">Luis Bandres</h2>')\n",
    "            gr.HTML('<p align=\"center\">Add description here</p>')\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # Load Data\n",
    "            gr.HTML('<h2 align=\"center\">Step 1: Load Data</h2>')\n",
    "            \n",
    "            upload_template = gr.inputs.File(type=\"bytes\", label=\"Upload Template\")\n",
    "            data_template = gr.outputs.HTML(label=\"Template\")\n",
    "            upload_template.upload(process_template, inputs=upload_template, outputs=data_template)\n",
    "            \n",
    "            upload_file = gr.inputs.File(type=\"bytes\", label=\"Upload New File\")\n",
    "            data_file = gr.outputs.HTML(label=\"New File\")\n",
    "            upload_file.upload(process_new_file, inputs=upload_file, outputs=data_file)\n",
    "\n",
    "        with gr.Column():\n",
    "            # Analyse Data\n",
    "            gr.HTML('<h2 align=\"center\">Step 3: Transform using LLM </h2>')\n",
    "            gr.HTML('<h3 align=\"left\">Dont leave this page while processing.</h3>')\n",
    "            gr.HTML('<p align=\"left\">This process could take 5 minutes approximately...</p>')\n",
    "            btn_analyse = gr.Button(\"Transform Table\")\n",
    "            data_proposal = gr.outputs.HTML(label=\"Data Mapping Result\")\n",
    "            chk_analysis = gr.Radio([\"Yes\", \"No\"], label=\"Data was mapped correctly?\")\n",
    "\n",
    "            # Generating Code\n",
    "            gr.HTML('<h2 align=\"center\">Step 4: Generate Python Code </h2>')\n",
    "            btn_python_code = gr.Button(\"Generate\")\n",
    "            text_python_code = gr.Textbox(value=\"Please Generate Python Code\",label=\"Python Code\")\n",
    "            chk_python_code = gr.Radio([\"Yes\", \"No\"], label=\"Python code is correct?\")\n",
    "            \n",
    "            # Edit Code\n",
    "            gr.HTML('<h2 align=\"center\">Step 5: Download Python Code </h2>')\n",
    "            gr.HTML('<h3 align=\"left\">Requisites:</h3>')\n",
    "            gr.HTML('<p align=\"left\">   * Step 2 must be confirmed.</p>')\n",
    "            gr.HTML('<p align=\"left\">   * Step 3 must be confirmed.</p>')\n",
    "            python_code_result = gr.outputs.HTML(label=\"Result Python Code\")\n",
    "            btn_download_python = gr.Button(\"Save Code\")\n",
    "            download_python = gr.outputs.File(label=\"Generated Python Code\")\n",
    "    \n",
    "    with gr.Row():    \n",
    "        with gr.Column():\n",
    "            # Chatbot\n",
    "            gr.HTML('<h2 align=\"center\">Step 6: Advanced Options </h2>')\n",
    "            gr.HTML('<b align=\"left\">This is a chatbot powered by OpenAI GPT 3.5 so it can help you to editing the code with AI Assistance. The Table Analysis and the Generated Python Code have been loaded to this assistant.</p>')\n",
    "            chatbot = gr.Chatbot(height=446, label='Chatbot') #just to fit the notebook\n",
    "            msg = gr.Textbox(label=\"Prompt\")\n",
    "            with gr.Accordion(label=\"Settings\",open=False):\n",
    "                system_context = gr.Textbox(label=\"System Context\", lines=2, value=\"A conversation between a user and an LLM-based AI python coding assistant. The assistant gives helpful, honest, and precise answers. The assistant must act as a programmer.\")\n",
    "            btn = gr.Button(\"Submit\")\n",
    "            clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "            \n",
    "    # Actions\n",
    "    btn_analyse.click(tables_analysis, inputs=None, outputs=[data_proposal,system_context])\n",
    "    chk_analysis.change(feedback_analysis,inputs=chk_analysis, outputs=None)\n",
    "\n",
    "    btn_python_code.click(generate_python_code,inputs=None,outputs=text_python_code)\n",
    "    chk_python_code.change(feedback_python_code,inputs=chk_python_code, outputs=python_code_result)\n",
    "\n",
    "    btn_download_python.click(download_python_code,inputs=None,outputs=download_python)\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot, system_context], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot, system_context], outputs=[msg, chatbot]) #Press enter to submit\n",
    "\n",
    "gr.close_all()\n",
    "demo.queue().launch(share=False, server_port=int(os.environ['GRADIO_SERVER_PORT']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db6819-bb08-44ba-8352-509ed24ed59a",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
